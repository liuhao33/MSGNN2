{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import utils.preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "save_prefix = r'./data/IMDB_processed/graph_split/'\n",
    "read_perfix = r'./data\\IMDB'\n",
    "num_ntypes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4661 stored elements in Compressed Sparse Row format>, <12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4661 stored elements in Compressed Sparse Row format>, <12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13983 stored elements in Compressed Sparse Row format>, <12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13983 stored elements in Compressed Sparse Row format>]\n",
      "[300, 300, 2339]\n",
      "(12772, 1256)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 读取.pkl文件\n",
    "with open(r'./data/IMDB/edges.pkl', 'rb') as f:\n",
    "    edges = pickle.load(f)\n",
    "\n",
    "# 使用读取的数据\n",
    "print(edges)\n",
    "\n",
    "with open(r'./data/IMDB/labels.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# 使用读取的数据\n",
    "print([len(data[p]) for p in range(len(data))])\n",
    "labels = np.concatenate([np.array(data[p]) for p in range(len(data))], axis = 0)\n",
    "\n",
    "with open(r'./data/IMDB/node_features.pkl', 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "\n",
    "# 使用读取的数据\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2939, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 4661],\n",
       "       [   1, 4662],\n",
       "       [   2, 4663],\n",
       "       ...,\n",
       "       [4658, 6357],\n",
       "       [4659, 6930],\n",
       "       [4660, 6492]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_1 = np.stack(edges[0].nonzero()).T\n",
    "edge_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2270,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(edges[1].nonzero()[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5841,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(edges[3].nonzero()[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  6931],\n",
       "       [    0,  7404],\n",
       "       [    0,  8558],\n",
       "       ...,\n",
       "       [ 4660,  8877],\n",
       "       [ 4660, 10769],\n",
       "       [ 4660, 12771]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_2 = np.stack(edges[2].nonzero()).T\n",
    "edge_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_1\n",
    "edge_1_pos_num = 932     # 20%\n",
    "idx = np.random.choice(len(edge_1), edge_1_pos_num, replace=False)\n",
    "edge_1_pos = edge_1[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(edges[0].A, dtype=bool) # lil_matrix or csr_matrix depends on tasks\n",
    "mask[np.ix_(np.unique(edges[0].nonzero()[0]),np.unique(edges[1].nonzero()[0]))] = True\n",
    "edges_1_neg_adj = np.logical_and(~(edges[0].A.astype('bool')), mask) \n",
    "edge_1_neg_candicate = np.stack(edges_1_neg_adj.nonzero()).T  # (10575809, 2)\n",
    "\n",
    "edge_1_neg_num = 932 \n",
    "idx = np.random.choice(len(edge_1_neg_candicate), edge_1_neg_num, replace=False)\n",
    "edge_1_neg = edge_1_neg_candicate[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type = np.array([1]*932).reshape(-1,1)\n",
    "pair_class = np.zeros(932, dtype= int)\n",
    "pair_class[:466] = 1\n",
    "pair_class = pair_class.reshape(-1,1)\n",
    "edge_1_pos = edge_1_pos[np.random.permutation(range(932))] # shuffle\n",
    "edge_1_neg = edge_1_neg[np.random.permutation(range(932))] # shuffle\n",
    "\n",
    "edge_1_val = np.concatenate([edge_type, np.concatenate([edge_1_pos[:466], edge_1_neg[:466]]), pair_class], axis=1)\n",
    "edge_1_test = np.concatenate([edge_type, np.concatenate([edge_1_pos[466:], edge_1_neg[466:]]), pair_class], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_2_pos_num = 2800     # 20%\n",
    "idx = np.random.choice(len(edge_2), edge_2_pos_num, replace=False)\n",
    "edge_2_pos = edge_2[idx]\n",
    "\n",
    "mask = np.zeros_like(edges[2].A, dtype=bool) # lil_matrix or csr_matrix depends on tasks\n",
    "mask[np.ix_(np.unique(edges[2].nonzero()[0]),np.unique(edges[3].nonzero()[0]))] = True\n",
    "edges_2_neg_adj = np.logical_and(~(edges[2].A.astype('bool')), mask) \n",
    "edge_2_neg_candicate = np.stack(edges_2_neg_adj.nonzero()).T  # (27210918, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_2_neg_num = 2800 \n",
    "idx = np.random.choice(len(edge_2_neg_candicate), edge_2_neg_num, replace=False)\n",
    "edge_2_neg = edge_2_neg_candicate[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type = np.array([2]*2800).reshape(-1,1)\n",
    "pair_class = np.zeros(2800, dtype= int)\n",
    "pair_class[:1400] = 1\n",
    "pair_class = pair_class.reshape(-1,1)\n",
    "edge_2_pos = edge_2_pos[np.random.permutation(range(2800))] # shuffle\n",
    "edge_2_neg = edge_2_neg[np.random.permutation(range(2800))] # shuffle\n",
    "\n",
    "edge_2_val = np.concatenate([edge_type, np.concatenate([edge_2_pos[:1400], edge_2_neg[:1400]]), pair_class], axis=1)\n",
    "edge_2_test = np.concatenate([edge_type, np.concatenate([edge_2_pos[1400:], edge_2_neg[1400:]]), pair_class], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_val = np.concatenate([edge_1_val,edge_2_val])\n",
    "imdb_test = np.concatenate([edge_1_test,edge_2_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## type_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4661, 2270, 5841]\n",
      "12772\n",
      "[    0  4661  6931 12772]\n"
     ]
    }
   ],
   "source": [
    "raw_dims = [4661, 2270, 5841]\n",
    "dim = 4661 + 2270 + 5841\n",
    "print(raw_dims)\n",
    "print(dim)\n",
    "\n",
    "prefix_operator = np.ones((num_ntypes+1, num_ntypes))\n",
    "prefix_operator = np.tril(prefix_operator, k=-1)   # 下三角矩阵\n",
    "prefix_operator = prefix_operator.dot(raw_dims).astype(int)\n",
    "print(prefix_operator)\n",
    "\n",
    "# 0 for movies 4661, 1 for directors 2270, 2 for actors 5841\n",
    "type_mask = np.zeros(dim,dtype=int)\n",
    "for i in range(num_ntypes):\n",
    "    type_mask[prefix_operator[i]:prefix_operator[i+1]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adjM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12772, 12772)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = edges[0] + edges[1] + edges[2] + edges[3]\n",
    "adjM = adj.A\n",
    "adjM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = {\n",
    "    'stem':[1,0,2],\n",
    "}\n",
    "ontology_pairs = [[1,0],[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_intances = utils.preprocess.get_intances_by_pair(adjM, type_mask, ontology, prefix_operator)\n",
    "#13983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13983\n",
      "          0     1      2\n",
      "0         0  4661   6931\n",
      "1         0  4661   7404\n",
      "2         0  4661   8558\n",
      "3        25  4661   6950\n",
      "4        25  4661   7069\n",
      "...     ...   ...    ...\n",
      "13978  4657  6929  10766\n",
      "13979  4657  6929  12769\n",
      "13980  4659  6930   8876\n",
      "13981  4659  6930   9918\n",
      "13982  4659  6930  10768\n",
      "\n",
      "[13983 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "subgraphs = utils.preprocess.get_ontology_subgraphs_v2(ontology, link_intances)\n",
    "\n",
    "subgraphs = subgraphs[subgraphs.columns.sort_values()]\n",
    "print(len(subgraphs))\n",
    "print(subgraphs)\n",
    "\n",
    "# 12828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1066434383392334\n",
      "13983\n",
      "          0     1      2\n",
      "0         0  4661   6931\n",
      "1         0  4661   7404\n",
      "2         0  4661   8558\n",
      "3        25  4661   6950\n",
      "4        25  4661   7069\n",
      "...     ...   ...    ...\n",
      "13978  4657  6929  10766\n",
      "13979  4657  6929  12769\n",
      "13980  4659  6930   8876\n",
      "13981  4659  6930   9918\n",
      "13982  4659  6930  10768\n",
      "\n",
      "[13983 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "link_intances = utils.preprocess.get_intances_by_pair(adjM, type_mask, ontology, prefix_operator)\n",
    "subgraphs = utils.preprocess.get_ontology_subgraphs_v3(ontology, link_intances)\n",
    "print(time.time()-t)\n",
    "subgraphs = subgraphs[subgraphs.columns.sort_values()]\n",
    "print(len(subgraphs))\n",
    "print(subgraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\ohnn\\lib\\site-packages\\scipy\\sparse\\_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 18 10:42:52 2024, finding pairs...\n",
      "Thu Apr 18 10:42:53 2024, finding pairs...\n",
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "ontology_pairs = [[1,0],[0,2]]\n",
    "res_adj = utils.preprocess.find_res_adj(adjM, subgraphs)\n",
    "incomplete_ontology_subgraphs, incomplete_subgraphs = utils.preprocess.find_incomplete_subgraph(adjM, type_mask, ontology_pairs, res_adj)\n",
    "print(len(incomplete_ontology_subgraphs))\n",
    "print(incomplete_subgraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directories if they do not exist\n",
    "for i in ['complete','incomplete']:\n",
    "    pathlib.Path(save_prefix + '{}'.format(i)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save data \n",
    "\n",
    "# mapping of node to subgraphs\n",
    "\n",
    "# mapping of node to node pairs \n",
    "\n",
    "# save schema\n",
    "np.save(save_prefix + 'complete/ontology.npy', ontology) # schema\n",
    "np.save(save_prefix + 'ontology_pairs.npy', ontology_pairs)\n",
    "# subgraph table\n",
    "np.save(save_prefix + 'complete/subgraphs.npy', subgraphs)\n",
    "# all nodes adjacency matrix\n",
    "scipy.sparse.save_npz(save_prefix + 'adjM.npz', scipy.sparse.csr_matrix(adjM))\n",
    "# all nodes (authors, papers, terms and conferences) features\n",
    "for i in range(num_ntypes):\n",
    "    scipy.sparse.save_npz(save_prefix + 'features_{}.npz'.format(i), scipy.sparse.csr_matrix(features[prefix_operator[i]:prefix_operator[i+1]]))\n",
    "# all nodes (authors, papers, terms and conferences) type labels\n",
    "np.save(save_prefix + 'node_types.npy', type_mask)\n",
    "# type prefix\n",
    "np.save(save_prefix + 'prefix_operator.npy', prefix_operator)\n",
    "# movie genre labels\n",
    "np.save(save_prefix + 'labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2993635128370164\n",
      "0.10362583136665951\n",
      "0.5970106557963241\n"
     ]
    }
   ],
   "source": [
    "# subgraphs train/validation/test splits\n",
    "rand_seed = 33333333\n",
    "train_val_idx, test_idx = train_test_split(np.arange(len(adjM)), test_size=0.113, random_state=rand_seed)\n",
    "a = np.isin(subgraphs,test_idx)\n",
    "a = a.sum(axis=1).astype('bool')\n",
    "subgraphs_test = subgraphs[a]\n",
    "subgraphs_tr_val = subgraphs[~a]\n",
    "subgraphs[a].shape\n",
    "print(subgraphs_test.shape[0]/len(subgraphs)) # 30% for test\n",
    "train_idx, val_idx = train_test_split(train_val_idx, test_size=0.051, random_state=rand_seed)\n",
    "b = np.isin(subgraphs_tr_val,val_idx)\n",
    "b = b.sum(axis=1).astype('bool')\n",
    "subgraphs_val = subgraphs_tr_val[b]\n",
    "subgraphs_train = subgraphs_tr_val[~b]\n",
    "subgraphs_tr_val[b].shape\n",
    "print(subgraphs_val.shape[0]/len(subgraphs)) # 10% for val\n",
    "print(len(subgraphs_train)/len(subgraphs)) # 60% for train\n",
    "\n",
    "np.savez(save_prefix + 'complete/' + 'subgraphs_train_val_test.npz',\n",
    "         subgraphs_train=subgraphs_train,\n",
    "         subgraphs_val=subgraphs_val,\n",
    "         subgraphs_test=subgraphs_test) # subgraph train&val&test\n",
    "# node split\n",
    "np.savez(save_prefix + 'complete/' + 'train_val_test_nodes.npz',\n",
    "         train_nodes=train_idx,\n",
    "         val_nodes=val_idx,\n",
    "         test_nodes=test_idx) # nodes train&val&test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11086676678824287"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjM[np.unique(test_idx)].sum()/adjM.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04620789530143746"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjM[np.unique(val_idx)].sum()/adjM.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[4423]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2939"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((label).nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12772, 1256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = IMDB['features']\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 4661 stored elements in Compressed Sparse Column format>\n",
      " <12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 4661 stored elements in Compressed Sparse Column format>\n",
      " <12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 13983 stored elements in Compressed Sparse Column format>\n",
      " <12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 13983 stored elements in Compressed Sparse Column format>]\n"
     ]
    }
   ],
   "source": [
    "edges = IMDB['edges']\n",
    "for i in range(len(edges)):\n",
    "    print(edges[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
