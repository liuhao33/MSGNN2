{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import utils.preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "save_prefix = r'./data/IMDB_processed/'\n",
    "read_perfix = r'./data\\IMDB'\n",
    "num_ntypes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load\n",
    "This IMDB dataset is from GTN(https://github.com/seongjunyun/Graph_Transformer_Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4661 stored elements in Compressed Sparse Row format>, <12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4661 stored elements in Compressed Sparse Row format>, <12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13983 stored elements in Compressed Sparse Row format>, <12772x12772 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13983 stored elements in Compressed Sparse Row format>]\n",
      "[300, 300, 2339]\n",
      "(12772, 1256)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r'./data/IMDB/edges.pkl', 'rb') as f:\n",
    "    edges = pickle.load(f)\n",
    "print(edges)\n",
    "\n",
    "with open(r'./data/IMDB/labels.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "print([len(data[p]) for p in range(len(data))])\n",
    "labels = np.concatenate([np.array(data[p]) for p in range(len(data))], axis = 0)\n",
    "\n",
    "with open(r'./data/IMDB/node_features.pkl', 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 4661],\n",
       "       [   1, 4662],\n",
       "       [   2, 4663],\n",
       "       ...,\n",
       "       [4658, 6357],\n",
       "       [4659, 6930],\n",
       "       [4660, 6492]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_1 = np.stack(edges[0].nonzero()).T\n",
    "edge_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2270,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(edges[1].nonzero()[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5841,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(edges[3].nonzero()[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## type_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4661, 2270, 5841]\n",
      "12772\n",
      "[    0  4661  6931 12772]\n"
     ]
    }
   ],
   "source": [
    "raw_dims = [4661, 2270, 5841]\n",
    "dim = 4661 + 2270 + 5841\n",
    "print(raw_dims)\n",
    "print(dim)\n",
    "\n",
    "prefix_operator = np.ones((num_ntypes+1, num_ntypes))\n",
    "prefix_operator = np.tril(prefix_operator, k=-1)   # 下三角矩阵\n",
    "prefix_operator = prefix_operator.dot(raw_dims).astype(int)\n",
    "print(prefix_operator)\n",
    "\n",
    "# 0 for movies 4661, 1 for directors 2270, 2 for actors 5841\n",
    "type_mask = np.zeros(dim,dtype=int)\n",
    "for i in range(num_ntypes):\n",
    "    type_mask[prefix_operator[i]:prefix_operator[i+1]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adjM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12772, 12772)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = edges[0] + edges[1] + edges[2] + edges[3]\n",
    "adjM = adj.A\n",
    "adjM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'stem':[1,0,2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "link_intances = utils.preprocess.get_intances(adjM, type_mask, schema, prefix_operator)\n",
    "subgraphs = utils.preprocess.get_schema_subgraphs_parallel(schema, link_intances)\n",
    "print(time.time()-t)\n",
    "subgraphs = subgraphs[subgraphs.columns.sort_values()]\n",
    "print(subgraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2993635128370164\n",
      "0.10362583136665951\n",
      "0.5970106557963241\n"
     ]
    }
   ],
   "source": [
    "# subgraphs train/validation/test splits\n",
    "rand_seed = 33333333\n",
    "train_val_idx, test_idx = train_test_split(np.arange(len(adjM)), test_size=0.113, random_state=rand_seed)\n",
    "a = np.isin(subgraphs,test_idx)\n",
    "a = a.sum(axis=1).astype('bool')\n",
    "subgraphs_test = subgraphs[a]\n",
    "subgraphs_tr_val = subgraphs[~a]\n",
    "subgraphs[a].shape\n",
    "print(subgraphs_test.shape[0]/len(subgraphs)) # 30% for test\n",
    "train_idx, val_idx = train_test_split(train_val_idx, test_size=0.051, random_state=rand_seed)\n",
    "b = np.isin(subgraphs_tr_val,val_idx)\n",
    "b = b.sum(axis=1).astype('bool')\n",
    "subgraphs_val = subgraphs_tr_val[b]\n",
    "subgraphs_train = subgraphs_tr_val[~b]\n",
    "subgraphs_tr_val[b].shape\n",
    "print(subgraphs_val.shape[0]/len(subgraphs)) # 10% for val\n",
    "print(len(subgraphs_train)/len(subgraphs)) # 60% for train\n",
    "\n",
    "# save data \n",
    "\n",
    "# save schema\n",
    "np.save(save_prefix + 'schema.npy', schema) # schema\n",
    "np.save(save_prefix + 'schema_pairs.npy', schema_pairs)\n",
    "# subgraph table\n",
    "np.save(save_prefix + 'subgraphs.npy', subgraphs)\n",
    "# all nodes adjacency matrix\n",
    "scipy.sparse.save_npz(save_prefix + 'adjM.npz', scipy.sparse.csr_matrix(adjM))\n",
    "# all nodes (authors, papers, terms and conferences) features\n",
    "for i in range(num_ntypes):\n",
    "    scipy.sparse.save_npz(save_prefix + 'features_{}.npz'.format(i), scipy.sparse.csr_matrix(features[prefix_operator[i]:prefix_operator[i+1]]))\n",
    "# all nodes (authors, papers, terms and conferences) type labels\n",
    "np.save(save_prefix + 'node_types.npy', type_mask)\n",
    "# type prefix\n",
    "np.save(save_prefix + 'prefix_operator.npy', prefix_operator)\n",
    "# movie genre labels\n",
    "np.save(save_prefix + 'labels.npy', labels)\n",
    "\n",
    "np.savez(save_prefix + 'subgraphs_train_val_test.npz',\n",
    "         subgraphs_train=subgraphs_train,\n",
    "         subgraphs_val=subgraphs_val,\n",
    "         subgraphs_test=subgraphs_test) # subgraph train&val&test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
